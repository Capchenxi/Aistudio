# 比赛经验分享

本次比赛的任务是人脸/人流密度检测，主要就是分辨图片中出现了的人的个数。

给出的数据集是train.zip 和train.json 的形式出现的，json图片中除了每张图中人物的个数还给了人的位置。

## 方法分析

我们在看到比赛项目的时候最重要的是要去决定自己准备用怎样的模型，因为模型定了之后，我们才能对自己所拥有的的数据进行明确的处理。因为一般确切的模型对应确切的训练集的格式。

### 分类问题

- 分类模型的数据格式一般为：( img, class)， 即输入一张图片，输出是个图片所属的类别。

- 分类模型的模型一般有：经典的VGG，AlexNet, ResNet，或者自己构造CNN网络结构。

- 对于该问题而言，如果使用分类问题，那么输入将是一张图片，输出是人数的类别（图中有1人为类1，图中有2人为类2，...，图中有N人为类N）

  **弊端**：1. 我们并不知道类别的范围，也就是说我们很难知道图片中最多有几人，因此最后分类的one-hot vector的长度很难确定； 2.就算类别的范围确定了，对于人流密度的测算到几百几千都是很有可能的，这样会导致one-hot vector过长；3.若是使用范围（1-50人为类1， 51-100人为类2）估算类别可以减少类别的个数，但是会造成结果的不准确。

### 回归问题

- 回归模型的数据格式一般为：( img, count), 即输入一张图片，输出是图片中人头的个数。
- 回归的模型一般有：自己构造CNN网络结构
- 对于该问题而言，最合适的是其实是回归模型，因为回归模型可以很好的对每一张图片中人流的数量进行估计。但是如何力利用这个回归模型，或者说放在什么样的框架中去用就有需要再好好研究一下了。

### 目标检测问题

- 目标检测问题的数据格式一般为：(img, box)(?)
- 目标检测问题的模型一般有：RCNN， Faster-RCNN
- 最开始我能想到的也是目标检测的问题，对于目标检测来讲，可能是可以最详细得翻译图片上人头个数的方法了。在目标检测的过程中，不仅最终的人数需要regression，每个人所在的位置框也是需要regression的，这样训练出来的模型更加可靠

### 人流密度问题

- 人流密度的数据格式一般为：(density_img，count)
- 人流密度问题的模型一般有：DSnet
- 人流密度的问题有专门的模型和数据格式，我也是第一次遇到。对于人流密度来讲，其实我们需要的是每个人头所在的点，然后以这个点为中心做一个高斯分布，之后原RGB图片就会变成一张密度图（类似热力图），人多的地方，染色最深。本实现算法中用到的就是这个处理数据的方式。

### 融合方法

多任务分支网络，结合网络预测密度图和回归图像中人的个数。

## 数据分析

- 数据描述：对于训练集中的图片会出现两种标注：1.边框标注（bbox）2.点标注（point）

  1. 所谓边框标注说的是图片中每个人的表示形式是一个方框(x,y,w,h)[左上x坐标，左上y坐标，宽，高] 或 (x1,y1,x2,y2)[左上x坐标，左上y坐标，右下x坐标，右下y坐标]
  2. 所谓点标注说的是图片中每个人的表示是一个点(x,y)，表示的很直观就是一个人头一个点。
  3. 还有一类会存在的点是ignore的点， 也就是图像中我们不考虑的人头点

- 数据特征：

  **观察自己的数据很重要**。

  对于图片来说，我们需要知道图片的分辨率是否相差很大，图片的来源是否统一，图片的场景是否一致。这些图片的特征都影响了我们对于之后模型的选择。

- 处理方法：

  1. 如果所选用的方法是目标检测的方法，那么大概率需要的是bbox类型的标注框。这时候可以将点标注的训练图像过滤掉（如果你不想麻烦的话），但切实可行的方法还是将点标注的换位bbox类型的标注。分享经验的同学是将每个标注点上下左右各拓展15个像素，得到一个方框表示人头。
  2. 如果所选用的方法是需要人头点的，那么bbox类型转为point类型就比较容易一些，可以取边框的中心位置，也可以取中心稍微靠上的位置（人头）。
  3. 对于不考虑的点，可将其坐标位置在图像上涂为全黑。

- 数据增广：

  分享老师提到一点数据增广。数据增广其实是很容易想到的一点，但是很多时候常常被忽略。我么可以进行离线的数据增广和在线的数据增广。所谓离线的就是在线下做好增广之后保存起来然后读取，这样就很容易造成对内存的需要过多的情况。在线的增广就是在训练的过程中，对图片进行变化，对训练集的数据量进行增加。可以对数据进行的变化有： **旋转，缩放，调节对比度，调节饱和度，增加边框（平均rgb值）**等等，在做数据变化的时候，对应的标注数据也要随着变化，这点不能忘。

## 模型调优

-  梯度爆照/ 梯度消失
  1. 更换激活函数 ReLu
  2. 添加Resnet 跳跃连接
  3. BatchNormalization
  4. 梯度截断
  5. 预训练+微调（也就是对经典网络的嫁接）
- 过拟合
  1. 数据增强
  2. 提前停止 （判断什么时候网络达到一个很好的效果，在训练集的精度上升的时候，测试集的精度可能会下降，可以添加损失/精度 的图来判断）
  3. 权重正则化 （L1:特征稀疏化； L2：对权重比较全面的关注，不会全都集中在同一个特征上）
  4. dropout
  5. 超参调优：学习率，batchsize，优化函数（Adam，SGD）
- 不收敛/ 不稳定

## 具体方法介绍

- MCNN （多尺寸卷积核提取特征然后结合在一起）
- CSRnet （基于空洞卷积，改变卷积核的感受野）
- RCNN （目标检测）







